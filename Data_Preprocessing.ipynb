{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "XAI_Phase_2_Data_Preprocessing",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries"
      ],
      "metadata": {
        "id": "mYIfXF8gkwEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gdown  # to download data from google drive\n",
        "import gzip   # to decompress downloaded data\n",
        "import shutil\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:56.929927Z",
          "iopub.execute_input": "2025-04-17T06:45:56.930412Z",
          "iopub.status.idle": "2025-04-17T06:45:56.93602Z",
          "shell.execute_reply.started": "2025-04-17T06:45:56.930369Z",
          "shell.execute_reply": "2025-04-17T06:45:56.934842Z"
        },
        "id": "GXyI6M1kkwED"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions to download raw data"
      ],
      "metadata": {
        "id": "htRff3FUkzSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data(folder_id):\n",
        "    '''\n",
        "    Downloads all content in a given google drive folder.\n",
        "\n",
        "    Args:\n",
        "    folder_id (str): google drive folder id which the content is to be downloaded from.\n",
        "    '''\n",
        "    print(\"downloading\")\n",
        "    url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
        "    # gdown URL formate\n",
        "    gdown.download_folder(url=url, output=\"./downloaded_folder\", quiet=False, use_cookies=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:56.937854Z",
          "iopub.execute_input": "2025-04-17T06:45:56.938218Z",
          "iopub.status.idle": "2025-04-17T06:45:56.95806Z",
          "shell.execute_reply.started": "2025-04-17T06:45:56.938187Z",
          "shell.execute_reply": "2025-04-17T06:45:56.95706Z"
        },
        "id": "FMta8ZfTkwEE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def decompress_gz(file_path, output_file_name):\n",
        "    '''\n",
        "    Decompresses given gzip file.\n",
        "\n",
        "    Args:\n",
        "    file_path (str): path of gzip file to be decompressed.\n",
        "    output_file_name (str): name to be save of file after decompression.\n",
        "    '''\n",
        "    print(\"decompressing\")\n",
        "    with gzip.open(file_path, 'rb') as f_in:\n",
        "        with open(output_file_name, 'wb') as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:56.959177Z",
          "iopub.execute_input": "2025-04-17T06:45:56.959475Z",
          "iopub.status.idle": "2025-04-17T06:45:56.980612Z",
          "shell.execute_reply.started": "2025-04-17T06:45:56.959451Z",
          "shell.execute_reply": "2025-04-17T06:45:56.979536Z"
        },
        "id": "gy74_QcqkwEE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def raw_data_downloading(file_path, downloaded_directory, decompressed_file_name):\n",
        "    '''\n",
        "    Downloads raw dataset.\n",
        "\n",
        "    Args:\n",
        "    file_path (str): path of dataset gzip file on google drive.\n",
        "    downloaded_directory (str): path of dataset gzip file after download.\n",
        "    decompressed_file_name (str): name to be save of file after decompression.\n",
        "    '''\n",
        "    download_data(file_path)\n",
        "    decompress_gz(downloaded_directory, decompressed_file_name)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:56.982523Z",
          "iopub.execute_input": "2025-04-17T06:45:56.982831Z",
          "iopub.status.idle": "2025-04-17T06:45:57.004146Z",
          "shell.execute_reply.started": "2025-04-17T06:45:56.9828Z",
          "shell.execute_reply": "2025-04-17T06:45:57.003153Z"
        },
        "id": "acCwLTPbkwEF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning"
      ],
      "metadata": {
        "id": "DBSL-0hDkwEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reading_data_into_dataframe(file_name):\n",
        "    '''\n",
        "    Saves raw dataset as a dataframe.\n",
        "\n",
        "    Args:\n",
        "    file_path (str): Dataset directory.\n",
        "\n",
        "    Returns:\n",
        "    dataframe: created dataframe\n",
        "    '''\n",
        "    print(\"reading\")\n",
        "    accepted_df = pd.read_csv(file_name, low_memory=False)\n",
        "    return accepted_df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.005592Z",
          "iopub.execute_input": "2025-04-17T06:45:57.005961Z",
          "iopub.status.idle": "2025-04-17T06:45:57.024565Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.00593Z",
          "shell.execute_reply": "2025-04-17T06:45:57.023461Z"
        },
        "id": "y2K2Hb5CkwEF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def high_null_drop(accepted_df, important_cols):\n",
        "    '''\n",
        "    Drops unimportant columns with high null count.\n",
        "\n",
        "    Args:\n",
        "    accepted_df (dataframe): Dataset dataframe.\n",
        "    important_cols (list(str)): Columns of importance with high null count to avoid dropping.\n",
        "    '''\n",
        "    print(\"col high null drop\")\n",
        "    number_of_entries = accepted_df.shape[0]\n",
        "    for col in accepted_df.columns.tolist():\n",
        "        if col in important_cols:\n",
        "            continue\n",
        "        tot_col_nulls = accepted_df[col].isna().sum()\n",
        "        if tot_col_nulls >= (0.2 * number_of_entries):\n",
        "            accepted_df.drop(col, axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.025772Z",
          "iopub.execute_input": "2025-04-17T06:45:57.026145Z",
          "iopub.status.idle": "2025-04-17T06:45:57.045011Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.026116Z",
          "shell.execute_reply": "2025-04-17T06:45:57.043921Z"
        },
        "id": "np3OZtJXkwEF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_null(accepted_df, col_2b_fixed, col_used_to_fix):\n",
        "    '''\n",
        "    Adjusts null values of a given column to 0 based on another related column.\n",
        "\n",
        "    Args:\n",
        "    accepted_df (dataframe): Dataset dataframe.\n",
        "    col_2b_fixed (str): Name of column that needs adjustement.\n",
        "    col_used_to_fix (str): Name of column used in fixing errored column.\n",
        "    '''\n",
        "    print(\"fixing delinq\")\n",
        "    wrong_col_index = accepted_df.columns.get_loc(col_2b_fixed)\n",
        "    fixer_col_index = accepted_df.columns.get_loc(col_used_to_fix)\n",
        "    for i in range (accepted_df.shape[0]):\n",
        "        if accepted_df.iat[i, fixer_col_index] == 0 and accepted_df.iat[i, wrong_col_index]:\n",
        "            accepted_df.iat[i, wrong_col_index] = 0"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.046045Z",
          "iopub.execute_input": "2025-04-17T06:45:57.046336Z",
          "iopub.status.idle": "2025-04-17T06:45:57.06354Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.046315Z",
          "shell.execute_reply": "2025-04-17T06:45:57.062428Z"
        },
        "id": "bKl2aoxqkwEG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_excessive_nulls(accepted_df):\n",
        "    '''\n",
        "    Drops all rows with null values.\n",
        "\n",
        "    Args:\n",
        "    accepted_df (dataframe): Dataset dataframe.\n",
        "    '''\n",
        "    print(\"nulled rows drop\")\n",
        "    for col in accepted_df.columns.tolist():\n",
        "        accepted_df = accepted_df[accepted_df[col].notna()]\n",
        "    return accepted_df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.064535Z",
          "iopub.execute_input": "2025-04-17T06:45:57.064811Z",
          "iopub.status.idle": "2025-04-17T06:45:57.084095Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.06478Z",
          "shell.execute_reply": "2025-04-17T06:45:57.08303Z"
        },
        "id": "oQdVe7UKkwEG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_unecessary_cols(accepted_df, columns):\n",
        "    '''\n",
        "    Drops columns unecessary for prediction.\n",
        "\n",
        "    Args:\n",
        "    accepted_df (dataframe): Dataset dataframe.\n",
        "    columns (list(str)): Columns' names that are unecessary.\n",
        "    '''\n",
        "    print(\"unnecessary cols drop\")\n",
        "    for col in columns:\n",
        "        if col in accepted_df.columns.tolist():\n",
        "            accepted_df.drop(col, axis=1, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.085121Z",
          "iopub.execute_input": "2025-04-17T06:45:57.08541Z",
          "iopub.status.idle": "2025-04-17T06:45:57.102139Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.085386Z",
          "shell.execute_reply": "2025-04-17T06:45:57.101091Z"
        },
        "id": "dUgK9ud2kwEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def encoding_target_var(df):\n",
        "    '''\n",
        "    Encodes the target variable categories into \"1\" for good credit & \"0\" for bad credit.\n",
        "\n",
        "    Args:\n",
        "    df (dataframe): Dataset dataframe.\n",
        "    '''\n",
        "    print(\"encoding trgt var\")\n",
        "    df['loan_status'] = df['loan_status'].replace('Current', \"1\")\n",
        "    df['loan_status'] = df['loan_status'].replace('Fully Paid', \"1\")\n",
        "    df['loan_status'] = df['loan_status'].replace('Charged Off', \"0\")\n",
        "    df['loan_status'] = df['loan_status'].replace('Late (31-120 days)', \"0\")\n",
        "    df['loan_status'] = df['loan_status'].replace('In Grace Period', \"1\")\n",
        "    df['loan_status'] = df['loan_status'].replace('Late (16-30 days)', \"1\")\n",
        "    df['loan_status'] = df['loan_status'].replace('Default', \"0\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.131432Z",
          "iopub.execute_input": "2025-04-17T06:45:57.131839Z",
          "iopub.status.idle": "2025-04-17T06:45:57.138739Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.131814Z",
          "shell.execute_reply": "2025-04-17T06:45:57.137964Z"
        },
        "id": "23Iad_hGkwEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(df):\n",
        "    '''\n",
        "    Randomly chooses rows with target \"1\" to match number of target \"0\" instances.\n",
        "\n",
        "    Args:\n",
        "    df (dataframe): Dataset dataframe.\n",
        "\n",
        "    Returns:\n",
        "    dataframe: Adjusted dataframe.\n",
        "    '''\n",
        "    print(\"sampling\")\n",
        "    subset_good = df[df['loan_status'] == \"1\"].sample(n=df[df['loan_status'] == \"0\"].shape[0],\n",
        "                                                      random_state=737)\n",
        "    subset_bad = df[df['loan_status'] == \"0\"]\n",
        "    df = pd.concat([subset_good, subset_bad])\n",
        "    df = df.sample(frac = 1)\n",
        "    df.reset_index(inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.140371Z",
          "iopub.execute_input": "2025-04-17T06:45:57.140749Z",
          "iopub.status.idle": "2025-04-17T06:45:57.16059Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.140726Z",
          "shell.execute_reply": "2025-04-17T06:45:57.1596Z"
        },
        "id": "oISdCPitkwEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def outlier_removal(df):\n",
        "    '''\n",
        "    Determines outliers using z-score then drop them.\n",
        "\n",
        "    Args:\n",
        "    df (dataframe): Dataset dataframe.\n",
        "\n",
        "    Returns:\n",
        "    dataframe: Adjusted dataframe.\n",
        "    '''\n",
        "    print(\"removing outliers\")\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    numeric_cols = [col for col in numeric_cols if col != 'loan_status']\n",
        "\n",
        "    z_scores = np.abs(stats.zscore(df[numeric_cols]))\n",
        "\n",
        "    threshold_z = 3  # thershold to determine outlier\n",
        "\n",
        "    outlier_rows = (z_scores > threshold_z).any(axis=1)\n",
        "\n",
        "    df = df[~outlier_rows]  # removal of outliers\n",
        "\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.161654Z",
          "iopub.execute_input": "2025-04-17T06:45:57.162005Z",
          "iopub.status.idle": "2025-04-17T06:45:57.179659Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.16198Z",
          "shell.execute_reply": "2025-04-17T06:45:57.178602Z"
        },
        "id": "qQDW2cSekwEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def standardizing(df):\n",
        "    '''\n",
        "    Standardizing all numeric columns of dataframe.\n",
        "\n",
        "    Args:\n",
        "    df (dataframe): Dataset dataframe.\n",
        "    '''\n",
        "    print(\"standardizing\")\n",
        "    scaler = StandardScaler()\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype != 'O' and col != \"loan_status\":\n",
        "            col_array = np.array(df[col])\n",
        "            col_array = col_array.reshape(-1, 1)\n",
        "            scaler.fit(col_array)\n",
        "            df[col] = scaler.transform(col_array)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.181664Z",
          "iopub.execute_input": "2025-04-17T06:45:57.182023Z",
          "iopub.status.idle": "2025-04-17T06:45:57.20029Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.182Z",
          "shell.execute_reply": "2025-04-17T06:45:57.199338Z"
        },
        "id": "ao2PkG5GkwEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encoding(df):\n",
        "    '''\n",
        "    Label encodes all object columns of dataframe.\n",
        "\n",
        "    Args:\n",
        "    df (dataframe): Dataset dataframe.\n",
        "    '''\n",
        "    print(\"label encoding\")\n",
        "    le = LabelEncoder()\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == 'O':\n",
        "            le.fit(df[col])\n",
        "            df[col] = le.transform(df[col])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.201459Z",
          "iopub.execute_input": "2025-04-17T06:45:57.202049Z",
          "iopub.status.idle": "2025-04-17T06:45:57.224382Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.202017Z",
          "shell.execute_reply": "2025-04-17T06:45:57.22339Z"
        },
        "id": "voF3HL9UkwEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def data_cleaning(csv_file):\n",
        "    '''\n",
        "    Performs all data cleaning.\n",
        "\n",
        "    Args:\n",
        "    csv_file (str): CSV file of dataset\n",
        "\n",
        "    Returns:\n",
        "    dataframe: Cleaned dataframe.\n",
        "    '''\n",
        "    df = reading_data_into_dataframe(csv_file)\n",
        "    high_null_drop(df, [\"mths_since_last_delinq\", \"all_util\"])\n",
        "    fix_null(df, \"mths_since_last_delinq\", \"delinq_amnt\")\n",
        "    df = drop_excessive_nulls(df)\n",
        "    drop_unecessary_cols(df, [\"acceptD\", \"application_type\", \"creditPullD\", \"desc\",\n",
        "                   \"emp_title\", \"expD\", \"id\", \"listD\", \"mthsSinceMostRecentInq\",\n",
        "                   \"reviewStatusD\", \"title\", \"url\", \"zip_code\", \"sec_app_inq_last_6mths\"])\n",
        "    encoding_target_var(df)\n",
        "    df = sampling(df)\n",
        "    df = outlier_removal(df)\n",
        "    standardizing(df)\n",
        "    label_encoding(df)\n",
        "    df.drop(\"index\", axis=1, inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.22536Z",
          "iopub.execute_input": "2025-04-17T06:45:57.225692Z",
          "iopub.status.idle": "2025-04-17T06:45:57.243636Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.225662Z",
          "shell.execute_reply": "2025-04-17T06:45:57.242438Z"
        },
        "id": "kKKcMlvakwEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "gkI-Xv-sk84x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_downloading(\"14ZG8utOf0Ry76w_T9rqrk5kdhhPIK84P\", '/kaggle/working/downloaded_folder/accepted_2007_to_2018Q4.csv.gz',\n",
        "                \"accepted.csv\")\n",
        "df = data_cleaning(\"accepted.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T06:45:57.244841Z",
          "iopub.execute_input": "2025-04-17T06:45:57.24518Z",
          "iopub.status.idle": "2025-04-17T06:52:50.70679Z",
          "shell.execute_reply.started": "2025-04-17T06:45:57.245149Z",
          "shell.execute_reply": "2025-04-17T06:52:50.705809Z"
        },
        "id": "xR5_Kax2kwEI",
        "outputId": "6a5c55e5-55e7-46b1-ea67-9c15d6306baa"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "reading\ncol high null drop\nfixing delinq\nnulled rows drop\nunnecessary cols drop\nencoding trgt var\nsampling\nremoving outliers\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/554659916.py:15: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n  z_scores = np.abs(stats.zscore(df[numeric_cols]))\n/tmp/ipykernel_31/554659916.py:19: RuntimeWarning: invalid value encountered in greater\n  outlier_rows = (z_scores > threshold_z).any(axis=1)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "standardizing\nlabel encoding\n(119286, 89)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   loan_amnt  funded_amnt  funded_amnt_inv  term  int_rate  installment  \\\n0   2.705294     2.705294         2.706406     0 -0.800165     3.010788   \n1   2.831965     2.831965         2.833102     1  0.936464     2.194618   \n2  -0.461473    -0.461473        -0.461004     0 -1.252451    -0.430270   \n3   2.071941     2.071941         2.072924     0  0.064333     2.605715   \n4  -0.461473    -0.461473        -0.461004     1  0.547154    -0.695067   \n\n   grade  sub_grade  emp_length  home_ownership  ...  percent_bc_gt_75  \\\n0      1          6           1               2  ...          1.691136   \n1      3         17           1               3  ...         -0.559035   \n2      0          2           4               3  ...         -1.121577   \n3      2         13           1               1  ...         -0.066810   \n4      3         15           1               3  ...          0.754502   \n\n   pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  total_bal_ex_mort  \\\n0              -0.42679  -0.151487        -0.413588           0.596422   \n1              -0.42679  -0.151487         0.089148           2.015826   \n2              -0.42679  -0.151487        -0.929017          -1.011710   \n3              -0.42679  -0.151487         0.193963          -0.319778   \n4              -0.42679  -0.151487        -0.648830          -0.004733   \n\n   total_bc_limit  total_il_high_credit_limit  hardship_flag  \\\n0        0.408736                    0.616524              0   \n1        0.481396                    2.387143              0   \n2       -0.238594                   -0.922073              0   \n3        0.791850                   -0.686441              0   \n4       -0.007405                    0.040135              0   \n\n   disbursement_method  debt_settlement_flag  \n0                    1                     0  \n1                    0                     0  \n2                    0                     0  \n3                    0                     0  \n4                    0                     0  \n\n[5 rows x 89 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>funded_amnt</th>\n      <th>funded_amnt_inv</th>\n      <th>term</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>grade</th>\n      <th>sub_grade</th>\n      <th>emp_length</th>\n      <th>home_ownership</th>\n      <th>...</th>\n      <th>percent_bc_gt_75</th>\n      <th>pub_rec_bankruptcies</th>\n      <th>tax_liens</th>\n      <th>tot_hi_cred_lim</th>\n      <th>total_bal_ex_mort</th>\n      <th>total_bc_limit</th>\n      <th>total_il_high_credit_limit</th>\n      <th>hardship_flag</th>\n      <th>disbursement_method</th>\n      <th>debt_settlement_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.705294</td>\n      <td>2.705294</td>\n      <td>2.706406</td>\n      <td>0</td>\n      <td>-0.800165</td>\n      <td>3.010788</td>\n      <td>1</td>\n      <td>6</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1.691136</td>\n      <td>-0.42679</td>\n      <td>-0.151487</td>\n      <td>-0.413588</td>\n      <td>0.596422</td>\n      <td>0.408736</td>\n      <td>0.616524</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.831965</td>\n      <td>2.831965</td>\n      <td>2.833102</td>\n      <td>1</td>\n      <td>0.936464</td>\n      <td>2.194618</td>\n      <td>3</td>\n      <td>17</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>-0.559035</td>\n      <td>-0.42679</td>\n      <td>-0.151487</td>\n      <td>0.089148</td>\n      <td>2.015826</td>\n      <td>0.481396</td>\n      <td>2.387143</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.461473</td>\n      <td>-0.461473</td>\n      <td>-0.461004</td>\n      <td>0</td>\n      <td>-1.252451</td>\n      <td>-0.430270</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>...</td>\n      <td>-1.121577</td>\n      <td>-0.42679</td>\n      <td>-0.151487</td>\n      <td>-0.929017</td>\n      <td>-1.011710</td>\n      <td>-0.238594</td>\n      <td>-0.922073</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.071941</td>\n      <td>2.071941</td>\n      <td>2.072924</td>\n      <td>0</td>\n      <td>0.064333</td>\n      <td>2.605715</td>\n      <td>2</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>-0.066810</td>\n      <td>-0.42679</td>\n      <td>-0.151487</td>\n      <td>0.193963</td>\n      <td>-0.319778</td>\n      <td>0.791850</td>\n      <td>-0.686441</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.461473</td>\n      <td>-0.461473</td>\n      <td>-0.461004</td>\n      <td>1</td>\n      <td>0.547154</td>\n      <td>-0.695067</td>\n      <td>3</td>\n      <td>15</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.754502</td>\n      <td>-0.42679</td>\n      <td>-0.151487</td>\n      <td>-0.648830</td>\n      <td>-0.004733</td>\n      <td>-0.007405</td>\n      <td>0.040135</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 89 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading cleaned data"
      ],
      "metadata": {
        "id": "9snOtKewk_Un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('df_cleaned.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T07:01:49.736433Z",
          "iopub.execute_input": "2025-04-17T07:01:49.73685Z",
          "iopub.status.idle": "2025-04-17T07:02:05.346793Z",
          "shell.execute_reply.started": "2025-04-17T07:01:49.736823Z",
          "shell.execute_reply": "2025-04-17T07:02:05.345546Z"
        },
        "id": "ArzXl2eakwEJ"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}